{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting Started with Naïve Bayes\n",
    "\n",
    "For our first Naïve Bayes classifier, we will see the Movie Reviews corpus that can be found [here](https://www.kaggle.com/datasets/nltkdata/movie-review). We will be using `movie_review.csv` specifically in these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading in the Dataset\n",
    "First, we need to load in the data from the file. Create a pandas dataframe containing the reviews. What information does the dataset contain? How many tags are in the dataset and how many instances of each category do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Splitting the Data\n",
    "\n",
    "Next, we shuffle the data and split it into training (80%), validation (10%) and test (10%) set. Scikit-Learn contains a method to split a dataset into two parts. (For Scikit-Learn installation help, check [here](https://scikit-learn.org/stable/install.html)). Fill in the blanks (represented by ...) in the following code block to split the data. You’ll have to apply this function twice to get a three-way split. Double check that the size of each dataset corresponds to what you expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = ...\n",
    "\n",
    "# Split the test data further into val and test set\n",
    "x_val, x_test, y_val, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tokenization and Bag-of-Words with Scikit-Learn\n",
    "\n",
    "For basic tokenization and bag-of-words feature extraction, we can use the `CountVectorizer` class from scikit-learn. We can fit and transform the `CountVectorizer` with the method `fit_transpose(raw_documents=...)`.\n",
    "([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer))\n",
    "\n",
    "The following commands may help you inspect the features:\n",
    "\n",
    "```python\n",
    "len(cv.vocabulary_)        # Number of words in the BOW\n",
    "cv.vocabulary_[\"boring\"]   # Index of \"boring\" in the feature matrix\n",
    "```\n",
    "\n",
    "Instantiate a vectorizer, then fit it to and transform the training dataset. How many words are in the bag-of-words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = ...\n",
    "x_train_bow = ...\n",
    "\n",
    "print(\"The number of words in the BOW is:\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Training and Prediction with a Multinomial Naïve Bayes Classifier\n",
    "\n",
    "Now, we train a multinomial Naïve Bayes classifier, using again existing libraries from scikit-learn, specifically `MultinomialNB`. ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)).\n",
    "\n",
    "\n",
    "Using the training BOW and corresponding tags, train the `MultinomialNB` using the `fit` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate the classifier object\n",
    "nb = ...\n",
    "# Train the classifier\n",
    "nb.fit(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate this model on the validation set. Remember, we first need to transform the validation set into the bag-of-words\n",
    "representation, using the same `CountVectorizer` already used for training. Then, predict the tags for the validation set using the classifier's `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_bow = ...\n",
    "predicted_y_val = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Evaluating the Classifier\n",
    "\n",
    "Now that we have the predicted tags for the validation set, let's evaluate the results. We can compare the predictions with the gold labels and compute different metrics using the `metrics` module in Scikit-Learn ([Documentation](https://scikit-learn.org/stable/api/sklearn.metrics.html)). \n",
    "\n",
    "We can calculate the accuracy, precision, recall, and f-score of the predictions as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "acc = metrics.accuracy_score(y_val, predicted_y_val)\n",
    "precision, recall, fscore, _ = metrics.precision_recall_fscore_support(y_val, predicted_y_val)\n",
    "\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F-score: {fscore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to precision, recall, and f-score, each class has their own score, but it is not clear which score goes to which class. Luckily, Scikit-Learn provides a “classification report” that shows performance metrics for all classes in a structured output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_val, predicted_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also display the raw confusion matrix, but note that scikit-learn displays the gold labels as the\n",
    "rows and the predicted labels as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_val, predicted_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the model do? How could you improve the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Improve the Classifier\n",
    "\n",
    "Using some of the ideas you listed in 1.5, create two other classifiers by changing some parameters either in the data extraction (CountVectorizer)\n",
    "or the training (MultinomialNB) step. Select the best of the three models based on the validation set\n",
    "performance and use that model for predicting and evaluating the test set (don’t forget to vectorize the\n",
    "test set with the appropriate CountVectorizer!).\n",
    "\n",
    "*Note: The corpus is already lowercased and tokenized, so there are limited options in that respect, but you may still try to improve tokenization.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
